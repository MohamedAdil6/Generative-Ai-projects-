{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MohamedAdil6/Generative-Ai-projects-/blob/main/chatbot.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eVbosX_XKaM-",
        "outputId": "9a59fb42-e27c-4177-e8c5-16220dbd468e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/bin/pip3\", line 10, in <module>\n",
            "    sys.exit(main())\n",
            "             ^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/main.py\", line 78, in main\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/__init__.py\", line 114, in create_command\n",
            "    module = importlib.import_module(module_path)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/lib/python3.11/importlib/__init__.py\", line 126, in import_module\n",
            "    return _bootstrap._gcd_import(name[level:], package, level)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"<frozen importlib._bootstrap>\", line 1204, in _gcd_import\n",
            "  File \"<frozen importlib._bootstrap>\", line 1176, in _find_and_load\n",
            "  File \"<frozen importlib._bootstrap>\", line 1147, in _find_and_load_unlocked\n",
            "  File \"<frozen importlib._bootstrap>\", line 690, in _load_unlocked\n",
            "  File \"<frozen importlib._bootstrap_external>\", line 940, in exec_module\n",
            "  File \"<frozen importlib._bootstrap>\", line 241, in _call_with_frames_removed\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/commands/install.py\", line 15, in <module>\n",
            "    from pip._internal.cli.req_command import (\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/cli/req_command.py\", line 18, in <module>\n",
            "    from pip._internal.index.collector import LinkCollector\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/index/collector.py\", line 38, in <module>\n",
            "    from pip._internal.network.session import PipSession\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/pip/_internal/network/session.py\", line 32, in <module>\n",
            "    from pip._vendor import requests, urllib3\n",
            "  File \"<frozen importlib._bootstrap>\", line 1207, in _handle_fromlist\n",
            "KeyboardInterrupt\n",
            "^C\n",
            "Welcome to the Chatbot! Type 'exit' to stop the conversation.\n",
            "You: exit\n",
            "Chat ended.\n"
          ]
        }
      ],
      "source": [
        "# Install the necessary library\n",
        "!pip install --upgrade google-generativeai\n",
        "\n",
        "# Import the necessary library\n",
        "import google.generativeai as genai\n",
        "import os\n",
        "\n",
        "# Set your API key from Google AI Studio\n",
        "GEMINI_API_KEY = \"AIzaSyCPNJcJxV_A2gWBB2z3DDL71TZTqmJ9jsw\"\n",
        "\n",
        "# Configure the Gemini API with your API key\n",
        "if not GEMINI_API_KEY:\n",
        "    raise ValueError(\"Gemini API Key not set. Please replace 'YOUR_API_KEY' with your actual key from Google AI Studio.\")\n",
        "\n",
        "genai.configure(api_key=GEMINI_API_KEY)\n",
        "\n",
        "# Initialize the model\n",
        "model = genai.GenerativeModel('gemini-1.5-flash')\n",
        "\n",
        "def generate_response(user_input):\n",
        "    \"\"\"Generates a response based on user input.\"\"\"\n",
        "    try:\n",
        "        # Use the model to generate content\n",
        "        response = model.generate_content(user_input)\n",
        "        return response.text\n",
        "    except Exception as e:\n",
        "        return f\"Error generating response: {e}\"\n",
        "\n",
        "# Chatbot loop\n",
        "def chatbot():\n",
        "    print(\"Welcome to the Chatbot! Type 'exit' to stop the conversation.\")\n",
        "\n",
        "    while True:\n",
        "        # Take user input\n",
        "        user_input = input(\"You: \")\n",
        "\n",
        "        if user_input.lower() == 'exit':\n",
        "            print(\"Chat ended.\")\n",
        "            break\n",
        "\n",
        "        # Generate a response using the model\n",
        "        bot_response = generate_response(user_input)\n",
        "\n",
        "        # Display the bot's response\n",
        "        print(f\"Bot: {bot_response}\\n\")\n",
        "\n",
        "# Run the chatbot\n",
        "if __name__ == \"__main__\":\n",
        "    chatbot()"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "AEpOkDCEiCQ3"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMFbR0Juu1ZDVPech2tl5b8",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}